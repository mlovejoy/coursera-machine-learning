---
title: "Coursera Machine Learning Project"
author: "MLovejoy"
date: "July 17, 2016"
output: html_document
---

# SUMMARY

This project attempts to predict the manner in which individuals did a weight lifting exercise. We know the "classe" variable is the target variable, to be predicted by all other variables. Ultimately we created a Random Forest model that predicts results with over 99% accuracy

# LOAD DATA

First we will load the data set and explore it a bit.

```{r}
pmltraining <- read.csv("pml-training.csv", header=TRUE)
pmltesting <- read.csv("pml-testing.csv", header=TRUE)
dim(pmltraining)
dim(pmltesting)
head(pmltraining$classe)
str(pmltraining)
```

We can see that it has 160 fields and under 20,000 records. Some of the fields seem to have many NAs and some are identifying fields that should not be used to predict.

We will load the several packages needed:

```{r}
library(caret)
library(ggplot2)
library(rattle)
library(rpart)
library(rpart.plot)
library(gbm)
```

# DATA PREPARATION

We can see that the first columns of data are index fields, names, and timestamps, so we will remove those unnecessary fields. However, we still have 154 possible predictor variables, so we need to perform some dimension reduction on this data set. This dimension reduction will improve processing time for the models and reduce multi-collinearity from correlated variables. To accomplish this, we will use the Near Zero Variance function in caret to remove these unnecessary variables.

```{r}
pmltraining <- pmltraining[, -(1:5)]
manyNA <- sapply(pmltraining, function(x) mean(is.na(x))) > 0.95
pmltraining <- pmltraining[ , manyNA == F]

nzv <- nearZeroVar(pmltraining, saveMetrics = TRUE)
pmltraining_nzv <-  pmltraining[ , nzv$nzv==FALSE]
dim(pmltraining_nzv)

summary(pmltraining_nzv$classe)
str(pmltraining_nzv)
```

No variables had zero variance, but 60 variables had near-zero variance and are now removed from the training data set. We are left with 54 variables, including the classe target variable.

Next we will partition the pmltraining data into training and testing sets. This pmltraining data set is meant for both training and testing models, as the separate pmltesting data set is reserved for evaluating the models for the purposes of the project.

```{r}
inTrain <- createDataPartition(y = pmltraining_nzv$classe, p=0.7, list=FALSE)
mytrain <- pmltraining_nzv[inTrain, ]
mytest <- pmltraining_nzv[-inTrain, ]

dim(mytrain); dim(mytest)
```

We now have the training set (consisting of 13,737 records) and the testing set (consisting of 5,885 records). Because of these fairly large partition sizes, I expect to have fairly small Out of Sample Error rates.

# MACHINE LEARNING ALGORITHMS

## 1. Decision Tree

We'll start with applying a Decision Tree because it can handle missing variables and outliers, and identify the most important variables for predicting Class E.

### Training

```{r}
set.seed(62384)

modFit_dt <- train(classe ~ ., data = mytrain, method = "rpart")
print(modFit_dt$finalModel)

fancyRpartPlot(modFit_dt$finalModel)
```

### Testing

```{r}
pred_dt <- predict(modFit_dt, newdata = mytest)

confusionMatrix(pred_dt, mytest$classe)
```

We can see that this model has very poor results - just better than tossing a fair coin. This model yields a very large Out of Sample Error, which is most likely due to overfitting. Let's try another model.

## 2. Random Forest

We'll now run a Random Forest model, using Train Control to reduce processing time.

### Training

```{r}
set.seed(62384)

modFit_rf <- train(classe ~ ., data = mytrain, method = "rf", ntree = 10, trControl = trainControl(method = "cv"))
print(modFit_rf$finalModel)
```

### Testing

```{r}
pred_rf <- predict(modFit_rf, newdata = mytest)

confusionMatrix(pred_rf, mytest$classe)
```

This model has over 99% accuracy, which is pretty good! But let's still try another one.

## 3. Generalized Boosted Regression

We'll also run a Generalized Boosted Regression Model (GBM).

### Training

```{r}
set.seed(62384)

fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 10)

modFit_gbm <- train(classe ~ ., data = mytrain, method = "gbm", trControl = fitControl, verbose = FALSE)
print(modFit_gbm$finalModel)
```

### Testing

```{r}
pred_gbm <- predict(modFit_gbm, newdata = mytest)

confusionMatrix(pred_gbm, mytest$classe)
```

This accuracy is also very good. But as we can see from the 3 models, the Random Forest model yielded the most accurate results, with GBM very close behind.

```{r, echo=FALSE}
colnames <- colnames(mytrain)
colnum <- which(colnames(pmltesting) %in% colnames)
pmltesting_red <- pmltesting[, c(colnum)]

pred_20 <- predict(modFit_rf, newdata = pmltesting_red)
table(pred_20)
```

Citation:

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

Read more: http://groupware.les.inf.puc-rio.br/har#ixzz4EXCjRVDj